{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP8IiuPrlG71"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcUOIusllG71"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_iVM6LzlG76"
      },
      "outputs": [],
      "source": [
        "!ls Ears\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfxMwGaDlG78"
      },
      "source": [
        "## Generate a `Dataset`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlZ8ConwlG78"
      },
      "outputs": [],
      "source": [
        "image_size = (180, 180)\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Ears\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Ears\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzcQSYRQlG79"
      },
      "source": [
        "## Visualize the data\n",
        "\n",
        "Here are the first 9 images in the training dataset. As you can see, label 1 is \"Elon\"\n",
        " and label 0 is \"Natalie\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n1mwO-UlG79"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yscbP8yzlG79"
      },
      "source": [
        "## Using image data augmentation\n",
        "\n",
        "When you don't have a large image dataset, it's a good practice to artificially\n",
        "introduce sample diversity by applying random yet realistic transformations to the\n",
        "training images, such as random horizontal flipping or small random rotations. This\n",
        "helps expose the model to different aspects of the training data while slowing down\n",
        " overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2THsrMAIlG7-"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oaCuA83lG7-"
      },
      "source": [
        "Let's visualize what the augmented samples look like, by applying `data_augmentation`\n",
        " repeatedly to the first image in the dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Q-UstZLlG7-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "    for i in range(9):\n",
        "        augmented_images = data_augmentation(images)\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StqYlQFClG8A"
      },
      "source": [
        "## Configure the dataset for performance\n",
        "\n",
        "Let's make sure to use buffered prefetching so we can yield data from disk without\n",
        " having I/O becoming blocking:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK1PPYqTlG8A"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.prefetch(buffer_size=32)\n",
        "val_ds = val_ds.prefetch(buffer_size=32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9zpvt4tlG8A"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We'll build a small version of the Xception network.\n",
        "\n",
        "Note that:\n",
        "\n",
        "- We start the model with the `data_augmentation` preprocessor, followed by a\n",
        " `Rescaling` layer.\n",
        "- We include a `Dropout` layer before the final classification layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FXdtF5alG8A"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_model(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    # Image augmentation block\n",
        "    x = data_augmentation(inputs)\n",
        "\n",
        "    # Entry block\n",
        "    x = layers.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x  # Set aside residual\n",
        "\n",
        "    for size in [128, 256, 512, 728]:\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "\n",
        "        # Project residual\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "        x = layers.add([x, residual])  # Add back residual\n",
        "        previous_block_activation = x  # Set aside next residual\n",
        "\n",
        "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"softmax\"\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
        "keras.utils.plot_model(model, show_shapes=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoI8in9NlG8B"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7-d0dVslG8B"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"),\n",
        "]\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "model.fit(\n",
        "    train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3Q97mHBlG8B"
      },
      "source": [
        "## Run inference on new data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdiaypv1lG8C"
      },
      "outputs": [],
      "source": [
        "img = keras.preprocessing.image.load_img(\n",
        "    \"Test/ELON_0183.png\", target_size=image_size\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = predictions[0]\n",
        "print(\n",
        "    \"This image is %.2f percent Natalie and %.2f percent Elon.\"\n",
        "    % (100 * (1 - score), 100 * score)\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "image_classification_from_scratch",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}